{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8OLn74/ygIt8/Us5+v0Yr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dimildizio/system_design/blob/main/NLLB_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install huggingface lib"
      ],
      "metadata": {
        "id": "71AG6SbS1rGh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "B8s9xcdCzT2P"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers rouge-score sacrebleu"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "drLby9M31wae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import files\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu, SmoothingFunction\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from rouge_score import rouge_scorer\n",
        "from typing import List"
      ],
      "metadata": {
        "id": "H6qx2zq2zeXB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJ6rSXT0BCNX",
        "outputId": "a358636f-86ba-4e9f-c79b-ef92d817734e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Specify huggingface access token to download model"
      ],
      "metadata": {
        "id": "l8r12BFV1kIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "access_token ='' #Put your huggingface token here"
      ],
      "metadata": {
        "id": "6UYE-GFm1Ny8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download tokenization models for rus and english corpus"
      ],
      "metadata": {
        "id": "6LsAdMvE1x07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eng_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"facebook/nllb-200-distilled-600M\", token=access_token)\n",
        "rus_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"facebook/nllb-200-distilled-600M\", src_lang=\"rus_Cyrl\", token=access_token)"
      ],
      "metadata": {
        "id": "2ryajZ7yz3Ju"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trying the out-of-the-box model"
      ],
      "metadata": {
        "id": "6HXBxELh23BI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create model"
      ],
      "metadata": {
        "id": "IIC-afo21_r7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\", token=access_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvULUr5w2BBc",
        "outputId": "d51da145-476f-4865-da31-7005893ac46f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:373: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create example data"
      ],
      "metadata": {
        "id": "2fRfcI2D2s-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = 'Шустрая бурая лисица прыгает через ленивого пса!'\n",
        "reference = 'The quick brown fox jumps over the lazy dog!'\n",
        "g_trans = 'The nimble brown fox jumps over the lazy dog!'"
      ],
      "metadata": {
        "id": "GuMCeuDq2Jsy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenize"
      ],
      "metadata": {
        "id": "HfgqQyUv20i_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rus_tok = rus_tokenizer(doc, return_tensors='pt')"
      ],
      "metadata": {
        "id": "s6yqXKVq3CtP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translate"
      ],
      "metadata": {
        "id": "6eFyfGlm5gVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translated_tokens = model.generate(\n",
        "    **rus_tok, forced_bos_token_id=rus_tokenizer.lang_code_to_id[\"eng_Latn\"], max_length=30)"
      ],
      "metadata": {
        "id": "u7PfGQXr3X-B"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translated = rus_tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0] #for multiple entries"
      ],
      "metadata": {
        "id": "5lCiHPP54n-K"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metrics"
      ],
      "metadata": {
        "id": "zqszBjes9QVJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **BLEU** - BiLingual Evaluation Understudy\n",
        ">cares more about word overlap.\n",
        "\n",
        ">Precision is more important.\n",
        "\n",
        "> Uses n-grams for evaluation.\n",
        "\n",
        ">Normalizes scores for text length.\n",
        "\n",
        ">Typical for machine translation.\n",
        "\n",
        ">Rewards model for producing matching with reference words.\n",
        "\n",
        "> Penalizes longer sentences.\n",
        "\n",
        "\n",
        "#### **ROUGE** - Recall-Oriented Understudy for Gisting Evaluation\n",
        "\n",
        ">Focused on capturing context (Gisting Evaluation).\n",
        "\n",
        ">Recall is more important. (Recall-Oriented)\n",
        "\n",
        "> Uses longest common subseq for evaluation.\n",
        "\n",
        "> Doesn't normalize scores for text length.\n",
        "\n",
        ">Typical for text summarization.\n",
        "\n",
        ">Rewards model if in general generated text represents the contexts of reference.\n",
        "\n",
        "> Longer texts have advantage for recall.\n",
        "\n",
        "\n",
        "#### **METEOR** - Metrics for Evaluation of Translation with Explicit ORdering\n",
        "\n",
        "> Takes word order into account.\n",
        "\n",
        "> Uses stemming and other techniques for synonyms and paraphrasing\n",
        "\n",
        "> F1 score is more important.\n",
        "\n",
        "> Uses unigrams (1 word) along with synonyms with preloaded WordNet synonym dictionary.\n",
        "\n",
        "> More robust in variations\n",
        "\n",
        "> Doesn't penalize longer texts\n",
        "\n",
        "> Typical for machine translation and text summarization.\n",
        "\n",
        "> Again: more flexible due to use of synonyms (more complex than word overlap)\n",
        "\n",
        "\n",
        "#### **TER** - Translation Edit Rate\n",
        "\n",
        "> Represents the **number of edits** needed to get from the hypothesis to the reference sentence. Lower is better.\n",
        "\n",
        "> Basically quantifies the dissimilarity of the reference and translation\n",
        "\n",
        "> Possible changes include: deletions, substitution, insertion, shifting\n",
        "\n",
        "> Used in machine translation and texts summarization.\n",
        "\n",
        "> Not included in commonly-used libs like nltk\n",
        "\n",
        "> More complex\n",
        "\n",
        "> No percentage score. Difficult to interprete the result. 0 edits is the best.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0wQMx_4eNdHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)"
      ],
      "metadata": {
        "id": "nWWX4ZK9AAqy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smoothing_zero_ngrams = SmoothingFunction()"
      ],
      "metadata": {
        "id": "Gw0G0gvKZjff"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def round_perc(num: float) -> float:\n",
        "  return round(num*100, 2)\n",
        "\n",
        "def get_sent_bleu(sentence: str, reference: str=reference) -> float:\n",
        "  '''n=3 gram'''\n",
        "  score = sentence_bleu([reference.split()], sentence.split(),\n",
        "                        weights = (0.25, 0.5, 0.25), smoothing_function=smoothing_zero_ngrams.method1) #weights define the 'window size'\n",
        "  return round_perc(score)\n",
        "\n",
        "def get_bleu(sentence: str, reference: str=reference) -> float:\n",
        "  score = corpus_bleu([[reference.split()]], [sentence.split()],\n",
        "                      smoothing_function=smoothing_zero_ngrams.method1)\n",
        "  return round_perc(score)\n",
        "\n",
        "def get_meteor(sentence: str, reference: str=reference) -> float:\n",
        "  score = meteor_score([reference.split()], sentence.split())\n",
        "  return round_perc(score)\n",
        "\n",
        "def get_rouge(sentence: str, reference: str=reference) -> float:\n",
        "  '''rouge-1 unigrams, individual words\n",
        "     rouge-2 bigrams, word pairs\n",
        "     rouge-L longest sequence'''\n",
        "  scores = Rouge.score(reference, sentence)\n",
        "  idict = {key:{} for key in scores}\n",
        "  for key in scores:\n",
        "    idict[key]['precision'] = str(round_perc(scores[key].precision))+'%'\n",
        "    idict[key]['recall'] = str(round_perc(scores[key].recall))+'%'\n",
        "    idict[key]['f1'] = str(round_perc(scores[key].fmeasure))+'%'\n",
        "  rouge_dict = {key: idict[key] for key in idict}\n",
        "  return rouge_dict"
      ],
      "metadata": {
        "id": "RfRl2zTLbe6J"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ter(hypothesis, reference=reference):\n",
        "    n = len(reference)\n",
        "    m = len(hypothesis)\n",
        "\n",
        "    # Init matrix for dynamic programming\n",
        "    dp = [[0] * (m + 1) for _ in range(n + 1)]\n",
        "\n",
        "    # Init first row and column\n",
        "    for i in range(n + 1):\n",
        "        dp[i][0] = i\n",
        "    for j in range(m + 1):\n",
        "        dp[0][j] = j\n",
        "\n",
        "    # Fill in the DP matrix\n",
        "    for i in range(1, n + 1):\n",
        "        for j in range(1, m + 1):\n",
        "            cost = 0 if reference[i - 1] == hypothesis[j - 1] else 1\n",
        "            dp[i][j] = min(dp[i - 1][j] + 1, dp[i][j - 1] + 1, dp[i - 1][j - 1] + cost)\n",
        "    return dp[n][m]"
      ],
      "metadata": {
        "id": "VrCPZrjBSMWq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test metrics"
      ],
      "metadata": {
        "id": "HMnMp8FvJScJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_metrics(reference, list_of_trans):\n",
        "  #print(f'Reference: {reference}\\n\\n')\n",
        "  transname = ['google translate', 'machine translation']\n",
        "  for name, func in zip(['sent_bleu', 'corpus_bleu', 'meteor', 'rouge'],   #, 'ter'],\n",
        "                        [get_sent_bleu, get_bleu, get_meteor, get_rouge]): #, ter]):\n",
        "    print('Metrics:', name)\n",
        "    symbol = '%'# if name != 'ter' else ' edits'\n",
        "    for num in range(len(list_of_trans)):\n",
        "      score = func(list_of_trans[num], reference)\n",
        "      print(f\"Translation: {transname[num]}: {score}{symbol}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "kE3ZDAvQ7qic"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload files to compare"
      ],
      "metadata": {
        "id": "9SviQJK-HDNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def onefile(files):\n",
        "  to_compare = []\n",
        "  for filename in files:\n",
        "    with open (filename+'.txt') as f:\n",
        "      new = f.readlines()\n",
        "    to_compare.append(''.join(new).replace('\\n', '').replace('\\t', ''))\n",
        "  return to_compare"
      ],
      "metadata": {
        "id": "o3oVw54AHMQ1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames = ['orig', 'gtrans', 'translation', 'reference']\n",
        "orig, gtrans, trans, ref = onefile(filenames)"
      ],
      "metadata": {
        "id": "l6s3vhAAJJ47"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_metrics(ref, [gtrans, trans])"
      ],
      "metadata": {
        "id": "BQBA0-Z6LCIB",
        "outputId": "8bccf3d7-a82f-415b-a298-7b42afaf5c32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics: sent_bleu\n",
            "Translation: google translate: 44.58%\n",
            "Translation: machine translation: 31.81%\n",
            "\n",
            "Metrics: corpus_bleu\n",
            "Translation: google translate: 35.96%\n",
            "Translation: machine translation: 23.07%\n",
            "\n",
            "Metrics: meteor\n",
            "Translation: google translate: 51.87%\n",
            "Translation: machine translation: 40.99%\n",
            "\n",
            "Metrics: rouge\n",
            "Translation: google translate: {'rouge1': {'precision': '86.07%', 'recall': '86.93%', 'f1': '86.5%'}, 'rouge2': {'precision': '55.29%', 'recall': '55.84%', 'f1': '55.56%'}, 'rougeL': {'precision': '67.4%', 'recall': '68.07%', 'f1': '67.73%'}}%\n",
            "Translation: machine translation: {'rouge1': {'precision': '81.98%', 'recall': '79.26%', 'f1': '80.6%'}, 'rouge2': {'precision': '44.41%', 'recall': '42.93%', 'f1': '43.66%'}, 'rougeL': {'precision': '58.16%', 'recall': '56.23%', 'f1': '57.18%'}}%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Flow"
      ],
      "metadata": {
        "id": "_7xNCqyOBep_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MachineTranslation:\n",
        "\n",
        "  def __init__(self, model, tokenizer, target_lang='eng_Latn', sent_len=300):\n",
        "    self.model=model\n",
        "    self.tokenizer = tokenizer\n",
        "    self.to_lang = target_lang\n",
        "    self.sent_len = sent_len\n",
        "    self.metrics_dict = {'TER':ter,\n",
        "                        'BLEU corpus':get_bleu,\n",
        "                        'BLEU sentence': get_sent_bleu,\n",
        "                        'METEOR': get_meteor,\n",
        "                        'ROUGE': get_rouge\n",
        "                         }\n",
        "\n",
        "\n",
        "  def tokenize(self, sent: str):\n",
        "    '''Tokenize input sentence'''\n",
        "    return self.tokenizer(sent, return_tensors='pt')\n",
        "\n",
        "\n",
        "  def translate(self, inputs):\n",
        "    '''\n",
        "    Generate translation\n",
        "    '''\n",
        "    return self.model.generate(\n",
        "      **inputs, forced_bos_token_id=self.tokenizer.lang_code_to_id[self.to_lang],\n",
        "      max_length=self.sent_len)\n",
        "\n",
        "\n",
        "  def get_decoded(self, toks) -> list:\n",
        "    '''\n",
        "    Convert vect tokens into sentences\n",
        "    '''\n",
        "    return self.tokenizer.batch_decode(toks, skip_special_tokens=True)\n",
        "\n",
        "\n",
        "  def generate_metrics(self, translation: str, reference: str) -> None:\n",
        "    '''\n",
        "    Use BLEU metrics and compare translated sent to the best translation\n",
        "    '''\n",
        "    #print(f'Reference: {reference}\\nTranslation: {translation}\\n')\n",
        "    for name, func in self.metrics_dict.items():\n",
        "      score = func(translation, reference)\n",
        "      self.print_metrics(translation, name, score)\n",
        "\n",
        "\n",
        "  def print_metrics(self, translation, metrics_name, score):\n",
        "    perc_sign = ' edits' if metrics_name == 'TER' else '%'\n",
        "    print(f\"{metrics_name} score: {score}{perc_sign}\")\n",
        "\n",
        "\n",
        "  def process_sentence(self, sent: str):\n",
        "    '''\n",
        "    main process for translation\n",
        "    '''\n",
        "    tokens = self.tokenize(sent)\n",
        "    translated_tokens = self.translate(tokens)\n",
        "    result = self.get_decoded(translated_tokens)\n",
        "    return result\n",
        "\n",
        "\n",
        "  def infer(self, sent: str, reference: str) -> None:\n",
        "    ''' TO BE CHANGED\n",
        "    Compare first sentence of the doc to the reference\n",
        "    '''\n",
        "    translation = self.process_sentence(sent)\n",
        "    self.generate_metrics(translation[0].lower(), reference.lower())"
      ],
      "metadata": {
        "id": "hf6PAdtxBfpg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MT = MachineTranslation(model, rus_tokenizer)"
      ],
      "metadata": {
        "id": "FzXbJmbGDO52"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MT.infer(doc, reference)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00Zg8gjiGubU",
        "outputId": "2dbcc17b-3ac9-4d1f-f5c7-cf3d46bd363c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TER score: 12 edits\n",
            "BLEU corpus score: 35.49%\n",
            "BLEU sentence score: 46.71%\n",
            "METEOR score: 65.43%\n",
            "ROUGE score: {'rouge1': {'precision': '66.67%', 'recall': '66.67%', 'f1': '66.67%'}, 'rouge2': {'precision': '50.0%', 'recall': '50.0%', 'f1': '50.0%'}, 'rougeL': {'precision': '66.67%', 'recall': '66.67%', 'f1': '66.67%'}}%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sample from dataset"
      ],
      "metadata": {
        "id": "aCzGS5cDW51M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a_few_sentences_rus = [\n",
        "'НЕЙТРОННАЯ РЕФЛЕКТОМЕТРИЯ В РОССИИ: ТЕКУЩЕЕ СОСТОЯНИЕ И ПЕРСПЕКТИВЫ',\n",
        "'В обзоре дано описание текущего состояния дел и перспектив развития в области нейтронной рефлектометрии на действующих и будущих нейтронных источниках Российской Федерации.',\n",
        "'В результате ввода в эксплуатацию новых инструментов на реакторах ИР-8 и ПИК число нейтронных рефлектометров в РФ должно удвоиться.',\n",
        "'В результате должен появиться набор инструментов, нацеленных на решение широкого круга задач в области физики, химии, биологии слоистых систем в интересах научного сообщества, а также для подготовки специалистов для дальнейшего развития и совершенствования данной методики.'\n",
        "]\n",
        "\n",
        "a_few_sentences_eng = [\n",
        "'Neutron Reflectometry in Russia: Current State and Prospects',\n",
        "'The review is devoted to the current state of affairs and prospects for development in the field of neutron reflectometry on the existing and future neutron sources in the Russian Federation.',\n",
        "'Due to the commissioning of new instruments at the IR-8 and PIK reactors, the number of neutron reflectometers in the Russian Federation should double.',\n",
        "'As a result, there must arise a set of instruments aimed at solving various problems in the fields of physics, chemistry, and biology of layered systems in the interests of the scientific community and to train experts for further development and improvement of this technique.'\n",
        "]\n",
        "\n",
        "pairs = list(zip(a_few_sentences_rus, a_few_sentences_eng))"
      ],
      "metadata": {
        "id": "gZ_9ZT_3W6EB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MT = MachineTranslation(model, rus_tokenizer)\n",
        "for pair in pairs:\n",
        "  rus, eng = [sent.lower() for sent in pair]\n",
        "  MT.infer(rus, eng)\n",
        "  print('\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaA-qysdXEwU",
        "outputId": "7950abdf-85b9-4efb-f38c-1e8481c50932"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TER score: 2 edits\n",
            "BLEU corpus score: 70.71%\n",
            "BLEU sentence score: 73.86%\n",
            "METEOR score: 86.48%\n",
            "ROUGE score: {'rouge1': {'precision': '87.5%', 'recall': '87.5%', 'f1': '87.5%'}, 'rouge2': {'precision': '71.43%', 'recall': '71.43%', 'f1': '71.43%'}, 'rougeL': {'precision': '87.5%', 'recall': '87.5%', 'f1': '87.5%'}}%\n",
            "\n",
            "\n",
            "\n",
            "TER score: 45 edits\n",
            "BLEU corpus score: 40.7%\n",
            "BLEU sentence score: 50.2%\n",
            "METEOR score: 64.53%\n",
            "ROUGE score: {'rouge1': {'precision': '82.14%', 'recall': '74.19%', 'f1': '77.97%'}, 'rouge2': {'precision': '55.56%', 'recall': '50.0%', 'f1': '52.63%'}, 'rougeL': {'precision': '78.57%', 'recall': '70.97%', 'f1': '74.58%'}}%\n",
            "\n",
            "\n",
            "\n",
            "TER score: 38 edits\n",
            "BLEU corpus score: 38.79%\n",
            "BLEU sentence score: 46.18%\n",
            "METEOR score: 59.32%\n",
            "ROUGE score: {'rouge1': {'precision': '64.0%', 'recall': '64.0%', 'f1': '64.0%'}, 'rouge2': {'precision': '50.0%', 'recall': '50.0%', 'f1': '50.0%'}, 'rougeL': {'precision': '64.0%', 'recall': '64.0%', 'f1': '64.0%'}}%\n",
            "\n",
            "\n",
            "\n",
            "TER score: 127 edits\n",
            "BLEU corpus score: 6.66%\n",
            "BLEU sentence score: 20.25%\n",
            "METEOR score: 55.6%\n",
            "ROUGE score: {'rouge1': {'precision': '73.81%', 'recall': '68.89%', 'f1': '71.26%'}, 'rouge2': {'precision': '31.71%', 'recall': '29.55%', 'f1': '30.59%'}, 'rougeL': {'precision': '57.14%', 'recall': '53.33%', 'f1': '55.17%'}}%\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try using a paragraph as a single entry"
      ],
      "metadata": {
        "id": "4IvqRH88hPfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextMachineTranslation(MachineTranslation):\n",
        "  def process_text(self, text: List[str]) -> str:\n",
        "    '''\n",
        "    main process for multi-sentence translation\n",
        "    '''\n",
        "    tokens = [self.tokenize(sent) for sent in text]\n",
        "    translated_tokens = [self.translate(token) for token in tokens]\n",
        "    translations = [self.get_decoded(toks)[0] for toks in translated_tokens]\n",
        "    result = ' '.join(translations)\n",
        "    return result\n",
        "\n",
        "\n",
        "  def infer(self, text: List[str], reference: List[str]) -> None:\n",
        "    ''' TO BE CHANGED\n",
        "    Compare the whole text to the reference\n",
        "    '''\n",
        "    translation = self.process_text(text)\n",
        "    reference = ' '.join(reference)\n",
        "    self.generate_metrics(translation.lower(), reference.lower())"
      ],
      "metadata": {
        "id": "TkSuUxzWha0k"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TMT = TextMachineTranslation(model, rus_tokenizer)\n",
        "TMT.infer(a_few_sentences_rus, a_few_sentences_eng)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y98aJ6_jiiZH",
        "outputId": "2588d126-6c8a-4556-9639-b4e09394fa27"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TER score: 200 edits\n",
            "BLEU corpus score: 37.95%\n",
            "BLEU sentence score: 45.9%\n",
            "METEOR score: 53.49%\n",
            "ROUGE score: {'rouge1': {'precision': '80.95%', 'recall': '77.98%', 'f1': '79.44%'}, 'rouge2': {'precision': '51.92%', 'recall': '50.0%', 'f1': '50.94%'}, 'rougeL': {'precision': '68.57%', 'recall': '66.06%', 'f1': '67.29%'}}%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try it on a whole article"
      ],
      "metadata": {
        "id": "zBFZKzMknlHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No ETL so far, no DB, just plain pd.read"
      ],
      "metadata": {
        "id": "fZPS-eSOqUNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'Krist_sample_data.xlsx'\n",
        "sheet_name = 'Krist2202003Borisov'\n",
        "df = pd.read_excel(filename, sheet_name=sheet_name).dropna(subset=['ru'])"
      ],
      "metadata": {
        "id": "7Kl7GBkmkslU",
        "outputId": "38c9898c-1e4a-4b08-8e07-4e393218a3d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b7bcf9e29a0b>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Krist_sample_data.xlsx'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msheet_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Krist2202003Borisov'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ru'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "orig_text = df['ru'].tolist()\n",
        "ref_text = df['en'].tolist()"
      ],
      "metadata": {
        "id": "g9IL3-HBmuT6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt_model = TextMachineTranslation(model, rus_tokenizer)\n",
        "#txt_model.infer(orig_text, ref_text)"
      ],
      "metadata": {
        "id": "SC_gEdTxyaxg"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "text_translated = txt_model.process_text(orig_text)"
      ],
      "metadata": {
        "id": "6GdpE0LQr6sV",
        "outputId": "95a50072-c829-4091-8c5d-309f05eaf74f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 14min 56s, sys: 217 ms, total: 14min 56s\n",
            "Wall time: 15min 10s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = 'translation.txt'\n",
        "with open(filepath, 'w') as f:\n",
        "  f.write(text_translated)\n",
        "\n",
        "files.download(filepath)"
      ],
      "metadata": {
        "id": "DUdjvq919G_B",
        "outputId": "6471a056-7761-4e2e-bcdd-d81cccd41ef5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_658dc839-dca6-4432-a78b-5795710e784d\", \"translation.txt\", 17471)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lnYz0COaq40i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Issues\n",
        "\n",
        "1. Choose proper metrics\n",
        "\n",
        "2. Evaluate metrics not for each sentence but for the whole text. I.e. cumulative metric or take average.\n"
      ],
      "metadata": {
        "id": "JFGU9pjecAO8"
      }
    }
  ]
}