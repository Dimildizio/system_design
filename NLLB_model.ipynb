{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWCtvbDK7Yg8JaHqHBACvs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dimildizio/system_design/blob/main/NLLB_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install huggingface lib"
      ],
      "metadata": {
        "id": "71AG6SbS1rGh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "B8s9xcdCzT2P"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install rouge-score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "drLby9M31wae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import files\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu, SmoothingFunction\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from rouge_score import rouge_scorer\n",
        "from typing import List"
      ],
      "metadata": {
        "id": "H6qx2zq2zeXB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJ6rSXT0BCNX",
        "outputId": "2e332eb0-df65-4911-8356-92519a4bce7d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Specify huggingface access token to download model"
      ],
      "metadata": {
        "id": "l8r12BFV1kIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "access_token ='' #Put your huggingface token here"
      ],
      "metadata": {
        "id": "6UYE-GFm1Ny8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download tokenization models for rus and english corpus"
      ],
      "metadata": {
        "id": "6LsAdMvE1x07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eng_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"facebook/nllb-200-distilled-600M\", token=access_token)\n",
        "rus_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"facebook/nllb-200-distilled-600M\", src_lang=\"rus_Cyrl\", token=access_token)"
      ],
      "metadata": {
        "id": "2ryajZ7yz3Ju"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trying the out-of-the-box model"
      ],
      "metadata": {
        "id": "6HXBxELh23BI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create model"
      ],
      "metadata": {
        "id": "IIC-afo21_r7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\", token=access_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvULUr5w2BBc",
        "outputId": "4bacb200-3366-4715-94d4-9e9dc4e6f51b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:373: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create example data"
      ],
      "metadata": {
        "id": "2fRfcI2D2s-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = 'Шустрая бурая лисица прыгает через ленивого пса!'\n",
        "reference = 'The quick brown fox jumps over the lazy dog!'\n",
        "g_trans = 'The nimble brown fox jumps over the lazy dog!'"
      ],
      "metadata": {
        "id": "GuMCeuDq2Jsy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenize"
      ],
      "metadata": {
        "id": "HfgqQyUv20i_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rus_tok = rus_tokenizer(doc, return_tensors='pt')"
      ],
      "metadata": {
        "id": "s6yqXKVq3CtP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translate"
      ],
      "metadata": {
        "id": "6eFyfGlm5gVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translated_tokens = model.generate(\n",
        "    **rus_tok, forced_bos_token_id=rus_tokenizer.lang_code_to_id[\"eng_Latn\"], max_length=30)"
      ],
      "metadata": {
        "id": "u7PfGQXr3X-B"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translated = rus_tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0] #for multiple entries"
      ],
      "metadata": {
        "id": "5lCiHPP54n-K"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metrics"
      ],
      "metadata": {
        "id": "zqszBjes9QVJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **BLEU** - BiLingual Evaluation Understudy\n",
        ">cares more about word overlap.\n",
        "\n",
        ">Precision is more important.\n",
        "\n",
        "> Uses n-grams for evaluation.\n",
        "\n",
        ">Normalizes scores for text length.\n",
        "\n",
        ">Typical for machine translation.\n",
        "\n",
        ">Rewards model for producing matching with reference words.\n",
        "\n",
        "> Penalizes longer sentences.\n",
        "\n",
        "\n",
        "#### **ROUGE** - Recall-Oriented Understudy for Gisting Evaluation\n",
        "\n",
        ">Focused on capturing context (Gisting Evaluation).\n",
        "\n",
        ">Recall is more important. (Recall-Oriented)\n",
        "\n",
        "> Uses longest common subseq for evaluation.\n",
        "\n",
        "> Doesn't normalize scores for text length.\n",
        "\n",
        ">Typical for text summarization.\n",
        "\n",
        ">Rewards model if in general generated text represents the contexts of reference.\n",
        "\n",
        "> Longer texts have advantage for recall.\n",
        "\n",
        "\n",
        "#### **METEOR** - Metrics for Evaluation of Translation with Explicit ORdering\n",
        "\n",
        "> Takes word order into account.\n",
        "\n",
        "> Uses stemming and other techniques for synonyms and paraphrasing\n",
        "\n",
        "> F1 score is more important.\n",
        "\n",
        "> Uses unigrams (1 word) along with synonyms with preloaded WordNet synonym dictionary.\n",
        "\n",
        "> More robust in variations\n",
        "\n",
        "> Doesn't penalize longer texts\n",
        "\n",
        "> Typical for machine translation and text summarization.\n",
        "\n",
        "> Again: more flexible due to use of synonyms (more complex than word overlap)\n",
        "\n",
        "\n",
        "#### **TER** - Translation Edit Rate\n",
        "\n",
        "> Represents the **number of edits** needed to get from the hypothesis to the reference sentence. Lower is better.\n",
        "\n",
        "> Basically quantifies the dissimilarity of the reference and translation\n",
        "\n",
        "> Possible changes include: deletions, substitution, insertion, shifting\n",
        "\n",
        "> Used in machine translation and texts summarization.\n",
        "\n",
        "> Not included in commonly-used libs like nltk\n",
        "\n",
        "> More complex\n",
        "\n",
        "> No percentage score. Difficult to interprete the result. 0 edits is the best.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0wQMx_4eNdHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)"
      ],
      "metadata": {
        "id": "nWWX4ZK9AAqy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smoothing_zero_ngrams = SmoothingFunction()"
      ],
      "metadata": {
        "id": "Gw0G0gvKZjff"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def round_perc(num: float) -> float:\n",
        "  return round(num*100, 2)\n",
        "\n",
        "def get_sent_bleu(sentence: str, reference: str=reference) -> float:\n",
        "  '''n=3 gram'''\n",
        "  score = sentence_bleu([reference.split()], sentence.split(),\n",
        "                        weights = (0.25, 0.5, 0.25), smoothing_function=smoothing_zero_ngrams.method1) #weights define the 'window size'\n",
        "  return round_perc(score)\n",
        "\n",
        "def get_bleu(sentence: str, reference: str=reference) -> float:\n",
        "  score = corpus_bleu([[reference.split()]], [sentence.split()],\n",
        "                      smoothing_function=smoothing_zero_ngrams.method1)\n",
        "  return round_perc(score)\n",
        "\n",
        "def get_meteor(sentence: str, reference: str=reference) -> float:\n",
        "  score = meteor_score([reference.split()], sentence.split())\n",
        "  return round_perc(score)\n",
        "\n",
        "def get_rouge(sentence: str, reference: str=reference) -> float:\n",
        "  '''rouge-1 unigrams, individual words\n",
        "     rouge-2 bigrams, word pairs\n",
        "     rouge-L longest sequence'''\n",
        "  scores = Rouge.score(reference, sentence)\n",
        "  idict = {key:{} for key in scores}\n",
        "  for key in scores:\n",
        "    idict[key]['precision'] = str(round_perc(scores[key].precision))+'%'\n",
        "    idict[key]['recall'] = str(round_perc(scores[key].recall))+'%'\n",
        "    idict[key]['f1'] = str(round_perc(scores[key].fmeasure))+'%'\n",
        "  rouge_dict = {key: idict[key] for key in idict}\n",
        "  return rouge_dict"
      ],
      "metadata": {
        "id": "RfRl2zTLbe6J"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ter(hypothesis, reference=reference):\n",
        "    n = len(reference)\n",
        "    m = len(hypothesis)\n",
        "\n",
        "    # Init matrix for dynamic programming\n",
        "    dp = [[0] * (m + 1) for _ in range(n + 1)]\n",
        "\n",
        "    # Init first row and column\n",
        "    for i in range(n + 1):\n",
        "        dp[i][0] = i\n",
        "    for j in range(m + 1):\n",
        "        dp[0][j] = j\n",
        "\n",
        "    # Fill in the DP matrix\n",
        "    for i in range(1, n + 1):\n",
        "        for j in range(1, m + 1):\n",
        "            cost = 0 if reference[i - 1] == hypothesis[j - 1] else 1\n",
        "            dp[i][j] = min(dp[i - 1][j] + 1, dp[i][j - 1] + 1, dp[i - 1][j - 1] + cost)\n",
        "    return dp[n][m]"
      ],
      "metadata": {
        "id": "VrCPZrjBSMWq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test metrics"
      ],
      "metadata": {
        "id": "HMnMp8FvJScJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Reference: {reference}\\n\\n')\n",
        "for translation in (g_trans, translated, reference):\n",
        "  score = get_bleu(translation, reference)\n",
        "  print(f\"Translation: {translation}\\nScore: {score}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kE3ZDAvQ7qic",
        "outputId": "6394a2b1-1e73-43d1-a6e2-1ce3d35f065b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reference: The quick brown fox jumps over the lazy dog!\n",
            "\n",
            "\n",
            "Translation: The nimble brown fox jumps over the lazy dog!\n",
            "Score: 75.06\n",
            "\n",
            "Translation: A shrewd brown fox jumps over a lazy dog!\n",
            "Score: 35.49\n",
            "\n",
            "Translation: The quick brown fox jumps over the lazy dog!\n",
            "Score: 100.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Flow"
      ],
      "metadata": {
        "id": "_7xNCqyOBep_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MachineTranslation:\n",
        "\n",
        "  def __init__(self, model, tokenizer, target_lang='eng_Latn', sent_len=300):\n",
        "    self.model=model\n",
        "    self.tokenizer = tokenizer\n",
        "    self.to_lang = target_lang\n",
        "    self.sent_len = sent_len\n",
        "    self.metrics_dict = {'TER':ter,\n",
        "                        'BLEU corpus':get_bleu,\n",
        "                        'BLEU sentence': get_sent_bleu,\n",
        "                        'METEOR': get_meteor,\n",
        "                        'ROUGE': get_rouge\n",
        "                         }\n",
        "\n",
        "\n",
        "  def tokenize(self, sent: str):\n",
        "    '''Tokenize input sentence'''\n",
        "    return self.tokenizer(sent, return_tensors='pt')\n",
        "\n",
        "\n",
        "  def translate(self, inputs):\n",
        "    '''\n",
        "    Generate translation\n",
        "    '''\n",
        "    return self.model.generate(\n",
        "      **inputs, forced_bos_token_id=self.tokenizer.lang_code_to_id[self.to_lang],\n",
        "      max_length=self.sent_len)\n",
        "\n",
        "\n",
        "  def get_decoded(self, toks) -> list:\n",
        "    '''\n",
        "    Convert vect tokens into sentences\n",
        "    '''\n",
        "    return self.tokenizer.batch_decode(toks, skip_special_tokens=True)\n",
        "\n",
        "\n",
        "  def generate_metrics(self, translation: str, reference: str) -> None:\n",
        "    '''\n",
        "    Use BLEU metrics and compare translated sent to the best translation\n",
        "    '''\n",
        "    #print(f'Reference: {reference}\\nTranslation: {translation}\\n')\n",
        "    for name, func in self.metrics_dict.items():\n",
        "      score = func(translation, reference)\n",
        "      self.print_metrics(translation, name, score)\n",
        "\n",
        "\n",
        "  def print_metrics(self, translation, metrics_name, score):\n",
        "    perc_sign = ' edits' if metrics_name == 'TER' else '%'\n",
        "    print(f\"{metrics_name} score: {score}{perc_sign}\")\n",
        "\n",
        "\n",
        "  def process_sentence(self, sent: str):\n",
        "    '''\n",
        "    main process for translation\n",
        "    '''\n",
        "    tokens = self.tokenize(sent)\n",
        "    translated_tokens = self.translate(tokens)\n",
        "    result = self.get_decoded(translated_tokens)\n",
        "    return result\n",
        "\n",
        "\n",
        "  def infer(self, sent: str, reference: str) -> None:\n",
        "    ''' TO BE CHANGED\n",
        "    Compare first sentence of the doc to the reference\n",
        "    '''\n",
        "    translation = self.process_sentence(sent)\n",
        "    self.generate_metrics(translation[0].lower(), reference.lower())"
      ],
      "metadata": {
        "id": "hf6PAdtxBfpg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MT = MachineTranslation(model, rus_tokenizer)"
      ],
      "metadata": {
        "id": "FzXbJmbGDO52"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MT.infer(doc, reference)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00Zg8gjiGubU",
        "outputId": "79d3544b-3ff8-4ba0-a01d-86c3b4f308f9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reference: the quick brown fox jumps over the lazy dog!\n",
            "Translation: a shrewd brown fox jumps over a lazy dog!\n",
            "\n",
            "TER score: 12 edits\n",
            "Bleu corpus score: 35.49%\n",
            "Bleu sentence score: 46.71%\n",
            "Meteor score: 65.43%\n",
            "Rouge score: {'rouge1': {'precision': '66.67%', 'recall': '66.67%', 'f1': '66.67%'}, 'rouge2': {'precision': '50.0%', 'recall': '50.0%', 'f1': '50.0%'}, 'rougeL': {'precision': '66.67%', 'recall': '66.67%', 'f1': '66.67%'}}%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sample from dataset"
      ],
      "metadata": {
        "id": "aCzGS5cDW51M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a_few_sentences_rus = [\n",
        "'НЕЙТРОННАЯ РЕФЛЕКТОМЕТРИЯ В РОССИИ: ТЕКУЩЕЕ СОСТОЯНИЕ И ПЕРСПЕКТИВЫ',\n",
        "'В обзоре дано описание текущего состояния дел и перспектив развития в области нейтронной рефлектометрии на действующих и будущих нейтронных источниках Российской Федерации.',\n",
        "'В результате ввода в эксплуатацию новых инструментов на реакторах ИР-8 и ПИК число нейтронных рефлектометров в РФ должно удвоиться.',\n",
        "'В результате должен появиться набор инструментов, нацеленных на решение широкого круга задач в области физики, химии, биологии слоистых систем в интересах научного сообщества, а также для подготовки специалистов для дальнейшего развития и совершенствования данной методики.'\n",
        "]\n",
        "\n",
        "a_few_sentences_eng = [\n",
        "'Neutron Reflectometry in Russia: Current State and Prospects',\n",
        "'The review is devoted to the current state of affairs and prospects for development in the field of neutron reflectometry on the existing and future neutron sources in the Russian Federation.',\n",
        "'Due to the commissioning of new instruments at the IR-8 and PIK reactors, the number of neutron reflectometers in the Russian Federation should double.',\n",
        "'As a result, there must arise a set of instruments aimed at solving various problems in the fields of physics, chemistry, and biology of layered systems in the interests of the scientific community and to train experts for further development and improvement of this technique.'\n",
        "]\n",
        "\n",
        "pairs = list(zip(a_few_sentences_rus, a_few_sentences_eng))"
      ],
      "metadata": {
        "id": "gZ_9ZT_3W6EB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MT = MachineTranslation(model, rus_tokenizer)\n",
        "for pair in pairs:\n",
        "  rus, eng = [sent.lower() for sent in pair]\n",
        "  MT.infer(rus, eng)\n",
        "  print('\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaA-qysdXEwU",
        "outputId": "17589b1f-6c23-474c-8836-9b9db22429cd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reference: neutron reflectometry in russia: current state and prospects\n",
            "Translation: neutron reflexometry in russia: current state and prospects\n",
            "\n",
            "TER score: 2 edits\n",
            "BLEU corpus score: 70.71%\n",
            "BLEU sentence score: 73.86%\n",
            "METEOR score: 86.48%\n",
            "ROUGE score: {'rouge1': {'precision': '87.5%', 'recall': '87.5%', 'f1': '87.5%'}, 'rouge2': {'precision': '71.43%', 'recall': '71.43%', 'f1': '71.43%'}, 'rougeL': {'precision': '87.5%', 'recall': '87.5%', 'f1': '87.5%'}}%\n",
            "\n",
            "\n",
            "\n",
            "Reference: the review is devoted to the current state of affairs and prospects for development in the field of neutron reflectometry on the existing and future neutron sources in the russian federation.\n",
            "Translation: the review describes the current state of affairs and development prospects in the field of neutron reflectorometry at the current and future neutron sources of the russian federation.\n",
            "\n",
            "TER score: 45 edits\n",
            "BLEU corpus score: 40.7%\n",
            "BLEU sentence score: 50.2%\n",
            "METEOR score: 64.53%\n",
            "ROUGE score: {'rouge1': {'precision': '82.14%', 'recall': '74.19%', 'f1': '77.97%'}, 'rouge2': {'precision': '55.56%', 'recall': '50.0%', 'f1': '52.63%'}, 'rougeL': {'precision': '78.57%', 'recall': '70.97%', 'f1': '74.58%'}}%\n",
            "\n",
            "\n",
            "\n",
            "Reference: due to the commissioning of new instruments at the ir-8 and pik reactors, the number of neutron reflectometers in the russian federation should double.\n",
            "Translation: as a result of the commissioning of new instruments at ir-8 and peak reactors, the number of neutron reflector meters per reactor should double.\n",
            "\n",
            "TER score: 38 edits\n",
            "BLEU corpus score: 38.79%\n",
            "BLEU sentence score: 46.18%\n",
            "METEOR score: 59.32%\n",
            "ROUGE score: {'rouge1': {'precision': '64.0%', 'recall': '64.0%', 'f1': '64.0%'}, 'rouge2': {'precision': '50.0%', 'recall': '50.0%', 'f1': '50.0%'}, 'rougeL': {'precision': '64.0%', 'recall': '64.0%', 'f1': '64.0%'}}%\n",
            "\n",
            "\n",
            "\n",
            "Reference: as a result, there must arise a set of instruments aimed at solving various problems in the fields of physics, chemistry, and biology of layered systems in the interests of the scientific community and to train experts for further development and improvement of this technique.\n",
            "Translation: the result should be a set of tools aimed at solving a wide range of problems in physics, chemistry, layered systems biology for the benefit of the scientific community, as well as for training specialists to further develop and improve this methodology.\n",
            "\n",
            "TER score: 127 edits\n",
            "BLEU corpus score: 6.66%\n",
            "BLEU sentence score: 20.25%\n",
            "METEOR score: 55.6%\n",
            "ROUGE score: {'rouge1': {'precision': '73.81%', 'recall': '68.89%', 'f1': '71.26%'}, 'rouge2': {'precision': '31.71%', 'recall': '29.55%', 'f1': '30.59%'}, 'rougeL': {'precision': '57.14%', 'recall': '53.33%', 'f1': '55.17%'}}%\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try using a paragraph as a single entry"
      ],
      "metadata": {
        "id": "4IvqRH88hPfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextMachineTranslation(MachineTranslation):\n",
        "  def process_text(self, text: List[str]) -> str:\n",
        "    '''\n",
        "    main process for multi-sentence translation\n",
        "    '''\n",
        "    tokens = [self.tokenize(sent) for sent in text]\n",
        "    translated_tokens = [self.translate(token) for token in tokens]\n",
        "    translations = [self.get_decoded(toks)[0] for toks in translated_tokens]\n",
        "    result = ' '.join(translations)\n",
        "    return result\n",
        "\n",
        "\n",
        "  def infer(self, text: List[str], reference: List[str]) -> None:\n",
        "    ''' TO BE CHANGED\n",
        "    Compare the whole text to the reference\n",
        "    '''\n",
        "    translation = self.process_text(text)\n",
        "    reference = ' '.join(reference)\n",
        "    self.generate_metrics(translation.lower(), reference.lower())"
      ],
      "metadata": {
        "id": "TkSuUxzWha0k"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TMT = TextMachineTranslation(model, rus_tokenizer)\n",
        "TMT.infer(a_few_sentences_rus, a_few_sentences_eng)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y98aJ6_jiiZH",
        "outputId": "62499cc1-ce74-485d-a152-53aea8bbfb46"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TER score: 200 edits\n",
            "BLEU corpus score: 37.95%\n",
            "BLEU sentence score: 45.9%\n",
            "METEOR score: 53.49%\n",
            "ROUGE score: {'rouge1': {'precision': '80.95%', 'recall': '77.98%', 'f1': '79.44%'}, 'rouge2': {'precision': '51.92%', 'recall': '50.0%', 'f1': '50.94%'}, 'rougeL': {'precision': '68.57%', 'recall': '66.06%', 'f1': '67.29%'}}%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try it on a whole article"
      ],
      "metadata": {
        "id": "zBFZKzMknlHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No ETL so far, no DB, just plain pd.read"
      ],
      "metadata": {
        "id": "fZPS-eSOqUNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'Krist_sample_data.xlsx'\n",
        "sheet_name = 'Krist2201004Bodnarchuk'\n",
        "df = pd.read_excel(filename, sheet_name=sheet_name).dropna(subset=['ru'])"
      ],
      "metadata": {
        "id": "7Kl7GBkmkslU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orig_text = df['ru'].tolist()\n",
        "ref_text = df['en'].tolist()"
      ],
      "metadata": {
        "id": "g9IL3-HBmuT6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt_model = TextMachineTranslation(model, rus_tokenizer)\n",
        "#txt_model.infer(orig_text, ref_text)"
      ],
      "metadata": {
        "id": "SC_gEdTxyaxg"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "text_translated = txt_model.process_text(orig_text)"
      ],
      "metadata": {
        "id": "6GdpE0LQr6sV",
        "outputId": "63471b91-fe05-4e4b-f1a2-a223752a93b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 40min 3s, sys: 3.82 s, total: 40min 7s\n",
            "Wall time: 40min 33s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = 'translation.txt'\n",
        "with open(filepath, 'w') as f:\n",
        "  f.write(text_translated)\n",
        "\n",
        "files.download(filepath)"
      ],
      "metadata": {
        "id": "DUdjvq919G_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# crashes colab due to the text size on metrics\n",
        "txt_model.generate_metrics(text_translated, ' '.join(ref_text))"
      ],
      "metadata": {
        "id": "VPgKzj2y8vzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Issues\n",
        "\n",
        "1. Choose proper metrics\n",
        "\n",
        "2. Evaluate metrics not for each sentence but for the whole text. I.e. cumulative metric or take average.\n"
      ],
      "metadata": {
        "id": "JFGU9pjecAO8"
      }
    }
  ]
}